{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from slugify import slugify\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "base_dir = \"任天堂株式会社-life\"\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1600\n",
      "Page 1800\n",
      "Page 2000\n",
      "Page 2200\n",
      "Page 2400\n",
      "Page 2600\n",
      "Page 2800\n",
      "Page 3000\n",
      "Page 3200\n",
      "Page 3400\n",
      "Page 3600\n",
      "Page 3800\n",
      "Page 4000\n",
      "Page 4200\n",
      "Page 4400\n",
      "Page 4600\n",
      "Page 4800\n",
      "Page 5000\n",
      "Page 5200\n",
      "Page 5400\n",
      "Page 5600\n",
      "Page 5800\n",
      "Page 6000\n",
      "45250\n"
     ]
    }
   ],
   "source": [
    "page_url = \"http://nintendoeverything.com/page/%d/\"\n",
    "urls = []\n",
    "for page in range(1476,6001):\n",
    "    if page % 200 == 0:\n",
    "        print(\"Page\", page)\n",
    "    url = page_url % page\n",
    "    \n",
    "    request = requests.get(url)\n",
    "    page_soup = BeautifulSoup(request.text, \"lxml\")\n",
    "    \n",
    "    panel1 = page_soup.find('div', {'id':'panel1'})\n",
    "    row__text_left = panel1.findAll('div', {'class':'row text-left'})\n",
    "    for row in row__text_left:\n",
    "        large_12__columns = row.find('div', {'class':'large-12 columns'})\n",
    "        a = large_12__columns.find('a')\n",
    "        urls.append(a.get('href'))\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45250\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59920\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "with open(os.path.join(base_dir, \"first.txt\"), \"r\") as read:\n",
    "    for line in read.readlines():\n",
    "        urls.append(line)\n",
    "        \n",
    "with open(os.path.join(base_dir, \"second.txt\"), \"r\") as read:\n",
    "    for line in read.readlines():\n",
    "        urls.append(line)\n",
    "        \n",
    "with open(os.path.join(base_dir, \"third.txt\"), \"r\") as read:\n",
    "    for line in read.readlines():\n",
    "        urls.append(line)\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math  \n",
    "\n",
    "def get_splits(total_items, splits):\n",
    "    batch_size = math.ceil(total_items / splits)\n",
    "    items_per_file =  math.ceil(total_items / batch_size)\n",
    "    splits = [((start*batch_size), \n",
    "               ((start * batch_size) + batch_size)\n",
    "               if (start * batch_size) + batch_size < total_items\n",
    "               else total_items)\n",
    "              for start in range(items_per_file)]\n",
    "    return splits\n",
    "    \n",
    "spl = get_splits(len(urls), 30)   \n",
    "test = 0\n",
    "for i,sp in enumerate(spl):\n",
    "    with open(os.path.join(base_dir, \"file-%06d-%06d.txt\" % (sp[0],sp[1])), \"w\") as w:\n",
    "        w.writelines(urls[sp[0]:sp[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
